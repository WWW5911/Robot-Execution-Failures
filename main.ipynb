{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.2 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "6aa14128b800140ad58ecab9d194dfc4e41eab4ae51d2f97bc26300102f16707"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "import math\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_lp1 = 'lp1_data.csv'\n",
    "df_lp2 = 'lp2_data.csv'\n",
    "df_lp3 = 'lp3_data.csv'\n",
    "df_lp4 = 'lp4_data.csv'\n",
    "df_lp5 = 'lp5_data.csv'\n",
    "dfs = [df_lp1, df_lp2, df_lp3, df_lp4, df_lp5]\n",
    "\n",
    "output_dim = 5\n",
    "full_data = []\n",
    "train_data = []\n",
    "lp_tmp = []\n",
    "for df in dfs:\n",
    "    tmp = pd.read_csv(df)\n",
    "    tmp = np.array(tmp)\n",
    "    for tp in tmp:\n",
    "        full_data.append(tp)\n",
    "\n",
    "np.random.shuffle(full_data)\n",
    "for tp in full_data:\n",
    "    train_data.append(tp[0:6])\n",
    "    lp_tmp.append(tp[6])\n",
    "\n",
    "train_label = np.zeros( ( len(train_data), output_dim ) )\n",
    "for i in range(len(lp_tmp)):\n",
    "    train_label[i][lp_tmp[i]-1] = 1     # let 1-5 turns to 0-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Partition(data, label, ratio):\n",
    "    t_data = data[0:int(len(data)*ratio) ]\n",
    "    t_label = label[0:int(len(label)*ratio) ]\n",
    "    verify_data = data[int(len(data)*ratio):len(data)]\n",
    "    verify_label = label[int(len(data)*ratio):len(data)]\n",
    "    return t_data, t_label, verify_data, verify_label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ratio = 0.8\n",
    "learning_rate = 0.03\n",
    "Epoch = 501\n",
    "tau = 0.001\n",
    "Layer = [8, 16, 16, 8]\n",
    "\n",
    "# add input dim and output dim\n",
    "Layer.insert(0, len(train_data[0]))\n",
    "Layer.append(output_dim)\n",
    "\n",
    "\n",
    "t_data, t_label, verify_data, verify_label = Partition(train_data, train_label, train_ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Sigmoid( n ):\n",
    "    l = []\n",
    "    for tmp in n:\n",
    "        if np.sum(tmp) >= 0:\n",
    "            l.append( 1 / (1 + math.exp(-tmp) ) )\n",
    "        else:\n",
    "            l.append(tmp / (1 + tmp))\n",
    "    return l\n",
    "\n",
    "# def sigmoid(data):\n",
    "#   if np.sum(data) >= 0:\n",
    "#     return  1 / ( 1 + math.exp(-np.sum(data)))\n",
    "#   else:\n",
    "#     return math.exp(np.sum(data)) / (1 + math.exp(np.sum(data)) )\n",
    "\n",
    "def Binary_crossEntropy(y, a):\n",
    "    CE = 0\n",
    "    for i in range( len(y) ):\n",
    "        CE += y[i] * math.log(a[i] + 1e-15 ) + (1 - y[i]) * math.log(1 - a[i] + 1e-15)\n",
    "    return CE\n",
    "def FeedForward(data, Weight, bias):\n",
    "    n = np.matmul( data, Weight) + bias.transpose() \n",
    "    return np.asarray( Sigmoid(n[0]) ) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Prediction(a):\n",
    "    index = 0\n",
    "    for i in range( len(a) ):\n",
    "        if a[i] > a[index]:\n",
    "            index = i\n",
    "    return index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "C:\\Users\\Astria\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\numpy\\core\\_asarray.py:102: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n  return array(a, dtype, copy=False, order=order)\n"
     ]
    }
   ],
   "source": [
    "def initialize(Layer):\n",
    "    Weights = []\n",
    "    Bias = []\n",
    "    for i in range ( 1, len(Layer) ):\n",
    "        weight = np.random.randn( Layer[i-1], Layer[i]) * np.sqrt(2 / Layer[i])\n",
    "        b = np.random.randn(Layer[i], 1) * np.sqrt(2 / Layer[i])\n",
    "        Weights.append(weight)\n",
    "        Bias.append(b)\n",
    "\n",
    "    # to make index of layer 1 from 0 to 1\n",
    "    Weights.insert(0, [])\n",
    "    Bias.insert(0, [])\n",
    "    Weights = np.asarray(Weights)\n",
    "    Bias = np.asarray(Bias)\n",
    "\n",
    "    return Weights, Bias\n",
    "\n",
    "Weights, Bias = initialize(Layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "ValueError",
     "evalue": "math domain error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-50-51791d6f877b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     29\u001b[0m         \u001b[1;31m# Calculate loss and training accuracy\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mflag\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 31\u001b[1;33m             \u001b[0mtotalLoss\u001b[0m \u001b[1;33m-=\u001b[0m \u001b[0mBinary_crossEntropy\u001b[0m\u001b[1;33m(\u001b[0m \u001b[0mt_label\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mL\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     32\u001b[0m             \u001b[0mp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mPrediction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mL\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mt_label\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-47-6ae65119737c>\u001b[0m in \u001b[0;36mBinary_crossEntropy\u001b[1;34m(y, a)\u001b[0m\n\u001b[0;32m     17\u001b[0m     \u001b[0mCE\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m         \u001b[0mCE\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mmath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1e-15\u001b[0m \u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mmath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1e-15\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     20\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mCE\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mFeedForward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mWeight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: math domain error"
     ]
    }
   ],
   "source": [
    "end_flag = False\n",
    "last_acc_T = 0\n",
    "last_acc_V = 0\n",
    "ce = []\n",
    "for ep in range(Epoch):\n",
    "    totalLoss = 0\n",
    "    L = len(Layer)-1\n",
    "    acc_t = 0\n",
    "    acc_v = 0\n",
    "    flag = True\n",
    "    for i in range(len(t_data)):\n",
    "        a = []\n",
    "        a.append( t_data[i] )\n",
    "        for l in range(1, L+1 ):\n",
    "            a.append(FeedForward(a[l-1],  Weights[l], Bias[l]) )\n",
    "        \n",
    "        # BackWard\n",
    "        Delta = [ a[L] - t_label[i] ]\n",
    "        for l in range(L-1, 0, -1):\n",
    "            Delta.insert(0, np.matmul( Delta[0], Weights[l+1].transpose() ) * ( a[l]*(1-a[l])  )  )\n",
    "        Delta.insert(0, [])\n",
    "        \n",
    "        # update Weights and Bias\n",
    "        for l in range(1, L+1):\n",
    "            t = np.matmul( Delta[l][np.newaxis].T, a[l-1][np.newaxis] )\n",
    "            Weights[l] = Weights[l] - learning_rate * t.T\n",
    "            Bias[l] = Bias[l] - learning_rate * Delta[l]\n",
    "        \n",
    "        # Calculate loss and training accuracy\n",
    "        if flag : \n",
    "            totalLoss -= Binary_crossEntropy( t_label[i], a[L] )\n",
    "            p = Prediction(a[L])\n",
    "            if t_label[i][p] == 1:\n",
    "                acc_t += 1\n",
    "\n",
    "    # Calculate verify accuracy\n",
    "    if flag : \n",
    "        for i in range( len(verify_data) ):\n",
    "            out = verify_data[i]\n",
    "            for l in range(1, L+1 ):\n",
    "                out = FeedForward(out, Weights[l], Bias[l])\n",
    "            p = Prediction(out)\n",
    "            if verify_label[i][p] == 1:\n",
    "                acc_v += 1\n",
    "\n",
    "        if last_acc_T < acc_t / len(t_data) and last_acc_V > acc_v / len(verify_data):\n",
    "            print(\"< Overtraining leads to overfitting >\" )\n",
    "            end_flag = True\n",
    "        last_acc_T = acc_t\n",
    "        last_acc_V = acc_v\n",
    "\n",
    "    if (ep+1) == Epoch:\n",
    "        print(\"< Reach maximum Epoch >\" )\n",
    "        end_flag = True\n",
    "\n",
    "    if flag and totalLoss / len(t_data) < tau:\n",
    "        print(\"< Loss is low enough ( tau: \" + str(tau) + \") >\"  )\n",
    "        end_flag = True\n",
    "\n",
    "    if end_flag:\n",
    "        print(\"Number of train_data: \" + str( len(t_data)) )\n",
    "        print(\"Number of verify_data: \" + str( len(verify_data)) )\n",
    "        print(\"Number of Hidden Layer: \" + str( len(Layer)-2) )\n",
    "        print(\"Number of Neuron in each Hidden Layer: \" + str(Layer[1:len(Layer)-1]) )\n",
    "        print(\"Learning Rate: \" + str(learning_rate) )\n",
    "        print(\"Epoch: \" + str(ep+1) )\n",
    "        print(\"Loss: \" + str( totalLoss / len(t_data) ))\n",
    "        print(\"Train accuracy: \" + str(acc_t / len(t_data)) )\n",
    "        print(\"Verify accuracy: \" + str(acc_v / len(verify_data)) )\n",
    "        break\n"
   ]
  }
 ]
}